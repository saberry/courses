---
title: "Unstructured Data Analytics"
description: |
  Regular Expressions
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


> Some people, when confronted with a problem, think, “I know, I'll use regular expressions.” Now they have two problems. 

## The 3 Goals of Regular Expressions

## What's The Pattern?

```{r, echo = FALSE}
data.frame(match = c("Mick", "Rick", "candlestick", "quick"), 
           no_match = c("fickleness", "unlicked", "Beck", "quickly"))
```

```{r, echo = FALSE}
data.frame(match = c("effusive", "fluted", "nihilistic", "suspenseful"), 
           no_match = c("otto", "abba", "trillion", "unfitting"))
```

```{r, echo = FALSE}
data.frame(match = c("civic", "level", "rotator", "tenet"), 
           no_match = c("pretest", "sunburn", "springer", "gourmet"))
```

```{r, echo = FALSE}
data.frame(match = c("intervisibility", "pseudoprimitivism", 
                     "micropoikilitic", "odontonosology"), 
           no_match = c("overregularly", "energetics", 
                        "observancy", "predisable"))
```

## Great Places To Practice And Learn

<a href="https://regexr.com/">regexr</a>

<a href="https://regex101.com/">regex101</a>

<a href="https://regexcrossword.com/">Will destroy your soul</a>

Throw these into regexr's or regex101's editor:

```
$100
$100.00
$GME
100
618-549-5326
Page 42
ElonMusk
I like this stock
Stonks
Were
Reeeee
Best
```

## Special Symbols

```
[
\
^
$
.
|
?
*
+
(
)
```

### Weird Things

```
\s
\t
\n
```


## Ranges and Sets

### Letters

```
[a-z]

```

### Digits

```
[1-9]

[[:digit:]]
```

### Punctuation

```
\.
\?
!
```


### Negation

```
[^aeiou]
```

### Posix Classes

```
[[:alpha:]]

[[:lower:]]

[[:punct:]]

[[:alnum:]]

[[:space:]]

[[:word:]]

[[:blank:]]
```

```{r}
testStrings <- c("test", "string", "123", "I'm here.")

grep("[[:blank:]]", testStrings, value = TRUE, perl = TRUE)
```


## Boundaries

```
\b
\w
```

## Groupings and Backreference

```
([a-z])
\1
```


## Using Regex

It might surprise you to find which has a more robust set of functions.

### R

base functions:

```{r, eval = FALSE}
test_strings <- c("Mick", "Rick", "candlestick", "quick", 
                  "fickleness", "unlicked", "Beck", "quickly")

# Complete the pattern

grep(pattern = "", x = test_strings, 
     perl = TRUE, value = TRUE)

# Which position is the match?

grepl(pattern = "", x = test_strings)

# Replace the match with something else.

gsub(pattern = "", replacement = "", x = test_strings)

# Find and extract a match

regmatches(regexpr())
```

stringr functions

```{r, eval = FALSE}
library(stringr)
str_which()
str_detect()
str_replace_all()
str_extract()
str_squish()
```


Here's an additional chunk of text to explore:

```{r}
wacky_text <- c("hereIam", "this is a test", 
          "I repeat, this is a test", 
          "N0. Rea11y", "anotherProblem")
```


### Python

```{python}
import re

p = re.compile('([a-z])([A-Z])')

wacky_text = ["hereIam", "this is a test", 
        "I repeat, this is a test", 
        "N0. Rea11y", "anotherProblem"]

matches = list(filter(p.search, wacky_text)) 

# Match is another method, but only works at the beginning of the string

re.sub(pattern = r"([a-z])([A-Z])", # The nonsense r is denoting a raw string.
       repl = "\\1 \\2", 
       string = "hereI am")



wacky_text = [re.sub(pattern = "([a-z])([A-Z])", repl = "\\1 \\2", string = wacky_text) 
  for wacky_text in wacky_text]

re.sub(pattern = "((?<=[a-z]))([A-Z])([a-z])", 
       repl = "\\1 \\2 \\3", 
       string = "hereIam")

```

Naturally, pandas has its own set of methods:

count, replace, contains, extract, findall, match, split

```{python, eval = FALSE}
import pandas as pd

pbpData = pd.read_csv("https://eightthirtyfour.com/nba/pbp/2000-01_pbp.csv")

pbpData['event'] = pbpData.HOMEDESCRIPTION.str.extract(r"([A-Z]{3,})")
```

## Common Regex Puzzles

\(*[0-9]{3}\)*-*\s*[0-9]{3}.*[0-9]{4}

